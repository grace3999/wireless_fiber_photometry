{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/opt/anaconda3/envs/analysis/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n"
     ]
    }
   ],
   "source": [
    "#getting and working with data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import datetime as dt\n",
    "import string\n",
    "import scipy\n",
    "\n",
    "#visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context(\"poster\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 15000)\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get data paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200803_MFB_blast_1m_CD56',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200731_MFB_sham_1m_CD53.2',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/.DS_Store',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200915_MFB_sham_1m_SA226.1',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201216_MFB_blast_1m_SA287.2',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/181117_MFB_sham_1m_practice1',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_sham_1m_CD54.1',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200917_MFB_blast_1m_SA234.3',\n",
       " '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201214_MFB_blast_1m_SA.287.1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of dir paths\n",
    "\n",
    "orig_path = '/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB'\n",
    "\n",
    "dir_path_list = os.listdir(orig_path)\n",
    "\n",
    "data_dir_paths = []\n",
    "for directory in dir_path_list:\n",
    "    int_path = orig_path + '/' + directory\n",
    "    data_dir_paths.append(int_path)\n",
    "    \n",
    "data_dir_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Hz/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200803_MFB_blast_1m_CD56\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200731_MFB_sham_1m_CD53.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/.DS_Store\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200915_MFB_sham_1m_SA226.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201216_MFB_blast_1m_SA287.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/181117_MFB_sham_1m_practice1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_sham_1m_CD54.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200917_MFB_blast_1m_SA234.3\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201214_MFB_blast_1m_SA.287.1\n",
      "/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200803_MFB_blast_1m_CD56\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200731_MFB_sham_1m_CD53.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/.DS_Store\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200915_MFB_sham_1m_SA226.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201216_MFB_blast_1m_SA287.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/181117_MFB_sham_1m_practice1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_sham_1m_CD54.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200917_MFB_blast_1m_SA234.3\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201214_MFB_blast_1m_SA.287.1\n",
      "/uA/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200803_MFB_blast_1m_CD56\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200731_MFB_sham_1m_CD53.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/.DS_Store\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200915_MFB_sham_1m_SA226.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201216_MFB_blast_1m_SA287.2\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/181117_MFB_sham_1m_practice1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_sham_1m_CD54.1\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200917_MFB_blast_1m_SA234.3\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201214_MFB_blast_1m_SA.287.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200803_MFB_blast_1m_CD56/Hz/BATCH_PC/STACKED_PC/Stacked_Current'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create list of file paths \n",
    "\n",
    "data_folder_names = ['/Hz/BATCH_PC/STACKED_PC/Stacked_Current', \n",
    "                     '/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current', \n",
    "                     '/uA/BATCH_PC/STACKED_PC/Stacked_Current']\n",
    "\n",
    "data_paths = []\n",
    "\n",
    "for name in data_folder_names:\n",
    "    print(name)\n",
    "    for directory in data_dir_paths:\n",
    "        print(directory)\n",
    "        int_path = str(directory + name)\n",
    "        data_paths.append(int_path)\n",
    "    \n",
    "data_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/201216_MFB_blast_1m_SA287.2/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/181117_MFB_sham_1m_practice1/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200917_MFB_blast_1m_SA234.3/tonicphasic/BATCH_PC/STACKED_PC/Stacked_Current\n",
      "/Users/abbieschindler/Documents/Schindler_Lab/Data/Anesthetized/MFB/200804_MFB_blast_1m_CD57/uA/BATCH_PC/STACKED_PC/Stacked_Current\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>05</th>\n",
       "      <th>10</th>\n",
       "      <th>20</th>\n",
       "      <th>40</th>\n",
       "      <th>60</th>\n",
       "      <th>stim_param</th>\n",
       "      <th>animal</th>\n",
       "      <th>date</th>\n",
       "      <th>stim_loc</th>\n",
       "      <th>group</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>Hz</td>\n",
       "      <td>CD56</td>\n",
       "      <td>200803</td>\n",
       "      <td>MFB</td>\n",
       "      <td>blast</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.636</td>\n",
       "      <td>3.102</td>\n",
       "      <td>15.267</td>\n",
       "      <td>17.136</td>\n",
       "      <td>Hz</td>\n",
       "      <td>CD53.2</td>\n",
       "      <td>200731</td>\n",
       "      <td>MFB</td>\n",
       "      <td>sham</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>Hz</td>\n",
       "      <td>CD57</td>\n",
       "      <td>200804</td>\n",
       "      <td>MFB</td>\n",
       "      <td>blast</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.278</td>\n",
       "      <td>0.557</td>\n",
       "      <td>3.908</td>\n",
       "      <td>16.587</td>\n",
       "      <td>17.155</td>\n",
       "      <td>Hz</td>\n",
       "      <td>SA226.1</td>\n",
       "      <td>200915</td>\n",
       "      <td>MFB</td>\n",
       "      <td>sham</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>2.268</td>\n",
       "      <td>4.748</td>\n",
       "      <td>23.966</td>\n",
       "      <td>30.821</td>\n",
       "      <td>23.530</td>\n",
       "      <td>Hz</td>\n",
       "      <td>SA287.2</td>\n",
       "      <td>201216</td>\n",
       "      <td>MFB</td>\n",
       "      <td>blast</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.796</td>\n",
       "      <td>1.587</td>\n",
       "      <td>4.346</td>\n",
       "      <td>16.272</td>\n",
       "      <td>24.107</td>\n",
       "      <td>Hz</td>\n",
       "      <td>practice1</td>\n",
       "      <td>181117</td>\n",
       "      <td>MFB</td>\n",
       "      <td>sham</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>-0.111</td>\n",
       "      <td>25.596</td>\n",
       "      <td>Hz</td>\n",
       "      <td>CD54.1</td>\n",
       "      <td>200804</td>\n",
       "      <td>MFB</td>\n",
       "      <td>sham</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>27.987</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>27.987</td>\n",
       "      <td>-0.352</td>\n",
       "      <td>Hz</td>\n",
       "      <td>SA234.3</td>\n",
       "      <td>200917</td>\n",
       "      <td>MFB</td>\n",
       "      <td>blast</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.9</td>\n",
       "      <td>1.134</td>\n",
       "      <td>1.804</td>\n",
       "      <td>12.109</td>\n",
       "      <td>29.617</td>\n",
       "      <td>29.414</td>\n",
       "      <td>Hz</td>\n",
       "      <td>SA.287.1</td>\n",
       "      <td>201214</td>\n",
       "      <td>MFB</td>\n",
       "      <td>blast</td>\n",
       "      <td>1m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time      05      10      20      40      60 stim_param     animal    date stim_loc  group  tp\n",
       "0  7.9  -0.111   25.596 -0.111   25.596 -0.111   Hz         CD56       200803  MFB      blast  1m\n",
       "0  7.9   0.502   0.636   3.102   15.267  17.136  Hz         CD53.2     200731  MFB      sham   1m\n",
       "0  7.9   25.596 -0.111   25.596 -0.111   25.596  Hz         CD57       200804  MFB      blast  1m\n",
       "0  7.9   0.278   0.557   3.908   16.587  17.155  Hz         SA226.1    200915  MFB      sham   1m\n",
       "0  7.9   2.268   4.748   23.966  30.821  23.530  Hz         SA287.2    201216  MFB      blast  1m\n",
       "0  7.9   0.796   1.587   4.346   16.272  24.107  Hz         practice1  181117  MFB      sham   1m\n",
       "0  7.9   25.596 -0.111   25.596 -0.111   25.596  Hz         CD54.1     200804  MFB      sham   1m\n",
       "0  7.9  -0.352   27.987 -0.352   27.987 -0.352   Hz         SA234.3    200917  MFB      blast  1m\n",
       "0  7.9   1.134   1.804   12.109  29.617  29.414  Hz         SA.287.1   201214  MFB      blast  1m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hz_cols = ['time', '05', '10', '20', '40', '60']\n",
    "tp_cols = ['time', 'tonic1', 'phasic1', 'tonic2', 'phasic2']\n",
    "uA_cols = ['time', '25', '50', '100', '150', '200', '300']\n",
    "\n",
    "data_Hz = pd.DataFrame()\n",
    "data_tonicphasic = pd.DataFrame()\n",
    "data_uA = pd.DataFrame()\n",
    "\n",
    "for file in data_paths:\n",
    "    \n",
    "    if file.split('/')[-5] == '.DS_Store':\n",
    "        continue\n",
    "    \n",
    "    try:\n",
    "        data_int = pd.read_table(file, header=None)\n",
    "        data_int = pd.DataFrame(data = data_int)\n",
    "    \n",
    "        #get max value for each stim param\n",
    "        max_vals = data_int[(data_int[0] > 4.9) & (data_int[0] < 8.0)].max(axis=0).values\n",
    "    \n",
    "        #get stim type from path    \n",
    "        stim_param = file.split('/')[-4]\n",
    "    \n",
    "        if stim_param == 'Hz':\n",
    "            #create df with max values\n",
    "            data_int_Hz = pd.DataFrame(data=max_vals).T\n",
    "            data_int_Hz.columns = Hz_cols\n",
    "            #fill meta data\n",
    "            data_int_Hz['stim_param'] = file.split('/')[-4]\n",
    "            data_int_Hz['animal'] = file.split('/')[-5].split('_')[4]\n",
    "            data_int_Hz['date'] = file.split('/')[-5].split('_')[0]\n",
    "            data_int_Hz['stim_loc'] = file.split('/')[-5].split('_')[1]\n",
    "            data_int_Hz['group'] = file.split('/')[-5].split('_')[2]\n",
    "            data_int_Hz['tp'] = file.split('/')[-5].split('_')[3]\n",
    "            #add to larger df\n",
    "            if data_Hz.shape[0] == 0:\n",
    "                data_Hz = data_int_Hz\n",
    "            else:\n",
    "                data_Hz = pd.concat([data_Hz, data_int_Hz], axis=0)\n",
    "    \n",
    "        if stim_param == 'tonicphasic':\n",
    "            #create df with max values\n",
    "            data_int_tp = pd.DataFrame(data=max_vals).T\n",
    "            data_int_tp.columns = tp_cols\n",
    "            #fill meta data\n",
    "            data_int_tp['stim_param'] = file.split('/')[-4]\n",
    "            data_int_tp['animal'] = file.split('/')[-5].split('_')[4]\n",
    "            data_int_tp['date'] = file.split('/')[-5].split('_')[0]\n",
    "            data_int_tp['stim_loc'] = file.split('/')[-5].split('_')[1]\n",
    "            data_int_tp['group'] = file.split('/')[-5].split('_')[2]\n",
    "            data_int_tp['tp'] = file.split('/')[-5].split('_')[3]\n",
    "            #add to larger df\n",
    "            if data_tonicphasic.shape[0] == 0:\n",
    "                data_tonicphasic = data_int_tp\n",
    "            else:\n",
    "                data_tonicphasic = pd.concat([data_tonicphasic, data_int_tp], axis=0)\n",
    "            \n",
    "            \n",
    "        if stim_param == 'uA':\n",
    "            #create df with max values\n",
    "            data_int_uA = pd.DataFrame(data=max_vals).T\n",
    "            data_int_uA.columns = uA_cols\n",
    "            #fill meta data\n",
    "            data_int_uA['stim_param'] = file.split('/')[-4]\n",
    "            data_int_uA['animal'] = file.split('/')[-5].split('_')[4]\n",
    "            data_int_uA['date'] = file.split('/')[-5].split('_')[0]\n",
    "            data_int_uA['stim_loc'] = file.split('/')[-5].split('_')[1]\n",
    "            data_int_uA['group'] = file.split('/')[-5].split('_')[2]\n",
    "            data_int_uA['tp'] = file.split('/')[-5].split('_')[3]\n",
    "            #add to larger df\n",
    "            if data_uA.shape[0] == 0:\n",
    "                data_uA = data_int_uA\n",
    "            else:\n",
    "                data_uA = pd.concat([data_uA, data_int_uA], axis=0)\n",
    "                \n",
    "    except:\n",
    "        print(file)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "data_Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Hz.to_csv('data_Hz.csv')\n",
    "data_tonicphasic.to_csv('data_tonicphasic.csv')\n",
    "data_uA.to_csv('data_uA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>tonic1</th>\n",
       "      <th>phasic1</th>\n",
       "      <th>tonic2</th>\n",
       "      <th>phasic2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>group</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blast</th>\n",
       "      <td>7.9</td>\n",
       "      <td>1.1130</td>\n",
       "      <td>4.179</td>\n",
       "      <td>0.924</td>\n",
       "      <td>4.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sham</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.3335</td>\n",
       "      <td>1.681</td>\n",
       "      <td>0.162</td>\n",
       "      <td>3.010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       time  tonic1  phasic1  tonic2  phasic2\n",
       "group                                        \n",
       "blast  7.9   1.1130  4.179    0.924   4.389  \n",
       "sham   7.9   0.3335  1.681    0.162   3.010  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove = ['CD56', 'CD57', 'CD54.1', 'SA234.3']\n",
    "data_tonicphasic[~data_tonicphasic['animal'].isin(remove)].groupby('group').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Hz[(data_Hz['time'] > 4.9) & (data_Hz['time'] < 8.0)].max(axis=0).values[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Hz_cols = ['time', '05', '10', '20', '40', '60']\n",
    "\n",
    "data = pd.read_table(data_paths[1], header=None)\n",
    "df = pd.DataFrame(data = data)\n",
    "df.columns = Hz_cols\n",
    "print(df.shape)\n",
    "\n",
    "df.max = df[(df['time'] > 4.9) & (df['time'] < 8.0)] .max(axis=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4h = df[df['TP'] == '4h']\n",
    "data_4h_blood = data_4h[data_4h['Sample'] == 'blood']\n",
    "data_4h_blood = data_4h_blood[data_4h_blood['Ship'] == 2]\n",
    "print(data_4h_blood.shape)\n",
    "data_4h_brain = data_4h[data_4h['Sample'] == 'brain']\n",
    "print(data_4h_brain.shape)\n",
    "\n",
    "data_6m = df[df['TP'] == '6m']\n",
    "data_6m_blood = data_6m[data_6m['Sample'] == 'blood']\n",
    "print(data_6m_blood.shape)\n",
    "data_6m_brain = data_6m[data_6m['Sample'] == 'brain']\n",
    "print(data_6m_brain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#viz \n",
    "\n",
    "for param in df.columns.values:\n",
    "    try:\n",
    "        print(param)\n",
    "        #viz\n",
    "        g = sns.catplot(x='TP', y=param, data=df, kind='bar', height=5, aspect=1, ci=68, hue='Group', \n",
    "                        col='Sample', sharey=False)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine sig diff cytokines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytokines = ['IL-1α', 'IL-1β',\n",
    "       'IL-2', 'IL-4', 'IL-5', 'IL-6', 'IL-7', 'IL-9', 'IL-10',\n",
    "       'IL-12(p40)', 'IL-12(p70)', 'IL-13', 'IL-15', 'IL-17', 'G-CSF',\n",
    "       'GM-CSF', 'INFγ', 'IP-10', 'MKC', 'MCP-1', 'MIP-1α', 'MIP-1β',\n",
    "       'MIP-2', 'RANTES', 'TNFα']\n",
    "\n",
    "data = data_4h_blood\n",
    "\n",
    "ttest_dict = {}\n",
    "\n",
    "for cytokine in cytokines:\n",
    "    print(cytokine)\n",
    "    try:\n",
    "        #viz\n",
    "        g = sns.catplot(x='Group', y=cytokine, data=data, kind='bar', height=3, aspect=1, ci=68)\n",
    "        plt.show()\n",
    "        \n",
    "        print('\\n')\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        x=data[data['Group'] == 1][cytokine].dropna().values\n",
    "        y=data[data['Group'] == 2][cytokine].dropna().values\n",
    "        ttest = scipy.stats.ttest_ind(x, y)\n",
    "        print(ttest[1], '\\n')\n",
    "        \n",
    "        #save to dict only if p value is below 0.1\n",
    "        if ttest[1] < 0.1:\n",
    "            ttest_dict[cytokine] = ttest\n",
    "\n",
    "    except:\n",
    "        print('can not run stats')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### corr and heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_cytokines = ttest_dict.keys()\n",
    "data1 = data[data['Group'] == 1]\n",
    "data2 = data[data['Group'] == 2]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "corr1 = data1[sig_cytokines].corr()\n",
    "mask = np.triu(np.ones_like(corr1, dtype=bool))\n",
    "ax = sns.heatmap(corr1, annot=True, vmin=-1, vmax=1, center=0, cmap = 'coolwarm', mask=mask,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "corr2 = data2[sig_cytokines].corr()\n",
    "mask = np.triu(np.ones_like(corr2, dtype=bool))\n",
    "ax = sns.heatmap(corr2, annot=True, vmin=-1, vmax=1, center=0, cmap = 'coolwarm', mask=mask,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "plt.yticks(rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z score and heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cytokines = ['IL-1α', 'IL-1β',\n",
    "       'IL-2', 'IL-4', 'IL-5', 'IL-6', 'IL-7', 'IL-9', 'IL-10',\n",
    "       'IL-12(p40)', 'IL-12(p70)', 'IL-13', 'IL-15', 'IL-17', 'G-CSF',\n",
    "       'GM-CSF', 'INFγ', 'IP-10', 'MKC', 'MCP-1', 'MIP-1α', 'MIP-1β',\n",
    "       'MIP-2', 'RANTES', 'TNFα']\n",
    "\n",
    "data_4h_blood_z = pd.DataFrame(data=scipy.stats.zscore(data_4h_blood[cytokines], axis=0, nan_policy='omit'), columns=cytokines)\n",
    "data_4h_blood_z['Group'] = data_4h_blood['Group'].values\n",
    "data_4h_blood_z.head()\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#scale data algo\n",
    "scaler = StandardScaler()\n",
    "ss = scaler.fit_transform(data_4h_blood[cytokines])\n",
    "data_4h_blood_ss = pd.DataFrame(data=ss, columns=cytokines)\n",
    "data_4h_blood_ss['Group'] = data_4h_blood['Group'].values\n",
    "data_4h_blood_ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_melt = pd.melt(data_4h_blood_z, id_vars=['Group'], \n",
    "                             value_vars=['IL-1α', 'IL-1β',\n",
    "       'IL-2', 'IL-4', 'IL-5', 'IL-6', 'IL-7', 'IL-9', 'IL-10',\n",
    "       'IL-12(p40)', 'IL-12(p70)', 'IL-13', 'IL-15', 'IL-17', 'G-CSF',\n",
    "       'GM-CSF', 'INFγ', 'IP-10', 'MKC', 'MCP-1', 'MIP-1α', 'MIP-1β',\n",
    "       'MIP-2', 'RANTES', 'TNFα']).dropna()\n",
    "\n",
    "df_melt['log_value'] = np.log10(df_melt['value'])\n",
    "\n",
    "df_melt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupby = df_melt.groupby(['Group', 'variable'])['value'].mean().reset_index()\n",
    "#viz\n",
    "groupby = groupby.pivot('Group', 'variable', \"value\")\n",
    "plt.figure(figsize=(15,3))\n",
    "ax = sns.heatmap(groupby, cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster and heat map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4h_blood.set_index(['Group', 'Animal']).drop(['Ship', 'Sample', 'TP'])\n",
    "#.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_4h_blood.set_index(['Group', 'Ship', 'Sample', 'Animal', 'TP']).dropna(axis=1)\n",
    "\n",
    "sns.clustermap(data_4h_blood.set_index(['Group', 'Ship', 'Sample', 'Animal', 'TP']).dropna(axis=1),\n",
    "               metric=\"euclidean\",  method=\"ward\", z_score=1,\n",
    "               annot=True, vmin=-1, vmax=1, center=0, cmap = 'coolwarm', \n",
    "               square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_4h_blood_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = dep_no_outliers.groupby([\"Group\"]).corr()\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use IQR (interquartile range) to determine outliers within each group. We will use the definition of outlier as any data point more than 1.5 IQRs below the first quartile or above the third quartile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new data frame organized by group so we can compute outliers for each group individually\n",
    "data_groups = df.unstack(level = -1)\n",
    "data_groups.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute quartiles, IQRs, and bounds for each parameter for each group\n",
    "quartile_1 = data_groups.quantile(0.25)\n",
    "quartile_3 = data_groups.quantile(0.75)\n",
    "iqr = quartile_3 - quartile_1\n",
    "lower_bound = quartile_1 - (iqr * 1.5)\n",
    "upper_bound = quartile_3 + (iqr * 1.5)\n",
    "lower_bound.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use bounds to exclude any data points outside of the bounds (outliers will be replaced with NaN)\n",
    "outliers = data_groups[(data_groups <= upper_bound) & (data_groups >= lower_bound)]\n",
    "#stack to return dataframe to original orientation\n",
    "dep_no_outliers = outliers.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_describe = pd.DataFrame(data = dep_no_outliers.groupby([\"Group\"]).describe())\n",
    "df_describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
